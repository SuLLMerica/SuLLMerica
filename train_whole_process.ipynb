{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for generating the training data for fine-tuning\n",
    "The dataset generated in this code is also available on huggingface in [SuLLMerica/TeleQnA-prompt-with-context-phinetune](https://huggingface.co/datasets/SuLLMerica/TeleQnA-prompt-with-context-phinetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ujson as json\n",
    "import os\n",
    "import traceback\n",
    "from Source.query import Query\n",
    "from Source.maneger_dataset import get_embeddings_by_labels\n",
    "from Source.generate_question import generate_questions_training\n",
    "from Source.enhancement_query import EnhancementQuery\n",
    "from Source.get_RAG_context import Get_RAG_Context\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "NUM_CLUSTERS = 18\n",
    "TOP_K_CLUSTERS = 8\n",
    "TOP_K_CHUNCKS = 5\n",
    "DATABASE_PATH=\"cluster_data_BisectingKMeans_18_250_chunksize.db\"\n",
    "TRAIN_FILE_PATH = \"./Data/TeleQnA_training.txt\"\n",
    "TRAIN_DATA_WITH_RAG_PATH = \"./Data/intermediates/TeleQnA_Train_With_RAG_Context.json\"\n",
    "PATH_TERMS_FILE = \"./Data/TermsAndDefinitions/terms_definitions.json\"\n",
    "PATH_ABBREVIATIONS_FILE = \"./Data/TermsAndDefinitions/abbreviations_definitions.json\"\n",
    "MODEL_ID = \"microsoft/phi-2\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data and generating context (only run if not using our provided data with generated context)\n",
    "Only run the next two sections if you want to manually generate the RAG context, if not run the [Getting the provided RAG data](#get-rag) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read both files and concatenate data\n",
    "with open(TRAIN_FILE_PATH) as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Create a class for enhancement\n",
    "enhacenment_query = EnhancementQuery(file_name_terms=PATH_TERMS_FILE, file_name_abbreviations=PATH_ABBREVIATIONS_FILE)\n",
    "\n",
    "\n",
    "\n",
    "train_data_json = []\n",
    "for question in train_data.keys():\n",
    "    question_id = int(question.split(\" \")[1])\n",
    "\n",
    "    terms, abreviations = enhacenment_query.define_TA_question(train_data[question][\"question\"])\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"question\": train_data[question][\"question\"],\n",
    "        \"question_id\": question_id,\n",
    "        \"terms\": terms,\n",
    "        \"abbreviations\": abreviations,\n",
    "        \"answer\": train_data[question][\"answer\"],\n",
    "        \"explanation\": train_data[question][\"explanation\"],\n",
    "        \"category\": train_data[question][\"category\"],\n",
    "        \n",
    "    }\n",
    "    if \"option 1\" in train_data[question]:\n",
    "        data[\"option 1\"] = train_data[question][\"option 1\"]\n",
    "    if \"option 2\" in train_data[question]:\n",
    "        data[\"option 2\"] = train_data[question][\"option 2\"]\n",
    "    if \"option 3\" in train_data[question]:\n",
    "        data[\"option 3\"] = train_data[question][\"option 3\"]\n",
    "    if \"option 4\" in train_data[question]:\n",
    "        data[\"option 4\"] = train_data[question][\"option 4\"]\n",
    "    if \"option 5\" in train_data[question]:\n",
    "        data[\"option 5\"] = train_data[question][\"option 5\"]\n",
    "    train_data_json.append(data)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating RAG Contexts:   0%|          | 0/1461 [02:08<?, ?question/s]\n"
     ]
    }
   ],
   "source": [
    " # Create a progress bar\n",
    "pb = tqdm(\n",
    "    train_data_json,\n",
    "    total=len(train_data_json),\n",
    "    desc=\"Generating RAG Contexts\",\n",
    "    unit=\"question\",\n",
    ")\n",
    "\n",
    "# Create a list to store the questions\n",
    "train_data_json_with_context=[]\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(DATABASE_PATH)\n",
    "\n",
    "\n",
    "# Iterate over the question_datas of the DataFrame\n",
    "for question_data in pb:\n",
    "\n",
    "\n",
    "    # Get the question\n",
    "    question = question_data[\"question\"]\n",
    "\n",
    "    # Get the options\n",
    "    options = {}\n",
    "    try:\n",
    "        option_1 = str(question_data[\"option 1\"])\n",
    "        if option_1 != \"nan\" and option_1 != \"\":\n",
    "            options[\"option 1\"] = option_1\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        option_2 = str(question_data[\"option 2\"])\n",
    "        if option_2 != \"nan\" and option_2 != \"\":\n",
    "            options[\"option 2\"] = option_2\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        option_3 = str(question_data[\"option 3\"])\n",
    "        if option_3 != \"nan\" and option_3 != \"\":\n",
    "            options[\"option 3\"] = option_3\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        option_4 = str(question_data[\"option 4\"])\n",
    "        if option_4 != \"nan\" and option_4 != \"\":\n",
    "            options[\"option 4\"] = option_4\n",
    "    except KeyError:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        option_5 = str(question_data[\"option 5\"])\n",
    "        if option_5 != \"nan\" and option_5 != \"\":\n",
    "            options[\"option 5\"] = option_5\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Get the terms and abbreviations\n",
    "    terms = None\n",
    "    if str(question_data[\"terms\"]) != \"nan\" and question_data[\"terms\"] != \"\":\n",
    "        terms = question_data[\"terms\"]\n",
    "    \n",
    "    abbreviations = None\n",
    "    if str(question_data[\"abbreviations\"]) != \"nan\" and question_data[\"abbreviations\"] != \"\":\n",
    "        abbreviations = question_data[\"abbreviations\"]\n",
    "    \n",
    "    \n",
    "    # Generate the RAG context\n",
    "\n",
    "    try:\n",
    "        context = Get_RAG_Context(question, conn, NUM_CLUSTERS, TOP_K_CLUSTERS, TOP_K_CHUNCKS)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    train_data_json_with_context.append({\n",
    "        \"question\": question,\n",
    "        \"question_id\": question_data[\"question_id\"],\n",
    "        \"options\": options,\n",
    "        \"terms\": terms,\n",
    "        \"abbreviations\": abbreviations,\n",
    "        \"context\": context,\n",
    "        \"answer\": question_data[\"answer\"],\n",
    "        \"explanation\": question_data[\"explanation\"],\n",
    "        \"category\": question_data[\"category\"],\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"get-rag\"></a>Getting the provided RAG data\n",
    "Run this section if you skipped the gernerating step earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATA_WITH_RAG_PATH, \"r\") as file:\n",
    "    train_data_json_with_context = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "\n",
    "dataset = []\n",
    "\n",
    "pb = tqdm(train_data_json_with_context, desc=\"Processing questions\", total=len(train_data_json_with_context), unit=\"Question\")\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for question_iter in pb:\n",
    "    # Get the question and answer\n",
    "    question = str(question_iter[\"question\"])\n",
    "\n",
    "    try:\n",
    "        option_1 = str(question_iter[\"options\"][\"option 1\"])\n",
    "        option_1_exists = True\n",
    "    except KeyError:\n",
    "        option_1 = \"\"\n",
    "        option_1_exists = False\n",
    "    try:\n",
    "        option_2 = str(question_iter[\"options\"][\"option 2\"])\n",
    "        option_2_exists = True\n",
    "    except KeyError:\n",
    "        option_2 = \"\"\n",
    "        option_2_exists = False\n",
    "    try:\n",
    "        option_3 = str(question_iter[\"options\"][\"option 3\"])\n",
    "        option_3_exists = True\n",
    "    except KeyError:\n",
    "        option_3 = \"\"\n",
    "        option_3_exists = False\n",
    "    try:\n",
    "        option_4 = str(question_iter[\"options\"][\"option 4\"])\n",
    "        option_4_exists = True\n",
    "    except KeyError:\n",
    "        option_4 = \"\"\n",
    "        option_4_exists = False\n",
    "    try:\n",
    "        option_5 = str(question_iter[\"options\"][\"option 5\"])\n",
    "        option_5_exists = True\n",
    "    except KeyError:\n",
    "        option_5_exists = False\n",
    "        option_5 = \"\"\n",
    "\n",
    "    # Update the question and answer in the DataFrame\n",
    "    merged_question = (\n",
    "        (\n",
    "            question\n",
    "            + \"\\n\"\n",
    "            + (\"\\n1. \" + option_1 if option_1_exists else \"\")\n",
    "            + (\"\\n2. \" + option_2 if option_2_exists else \"\")\n",
    "            + (\"\\n3. \" + option_3 if option_3_exists else \"\")\n",
    "            + (\"\\n4. \" + option_4 if option_4_exists else \"\")\n",
    "            + (\"\\n5. \" + option_5 if option_5_exists else \"\")\n",
    "        )\n",
    "        + \"\\n\\n\"\n",
    "        + \"Choose the correct option from the above options\"\n",
    "    )\n",
    "\n",
    "    # Prepare the answer\n",
    "    merged_answer = (\n",
    "        \"The correct option number is \"\n",
    "        + str(question_iter[\"answer\"])\n",
    "        + \"\\n\"\n",
    "        + \"Explanation: \"\n",
    "        + str(question_iter[\"explanation\"])\n",
    "    )\n",
    "\n",
    "    context = \"\"\n",
    "    for ret in question_iter[\"context\"]:\n",
    "        context += ret\n",
    "\n",
    "    full_context = (\n",
    "        f\"Considering the following context:\\n{str(context)}\\n\"\n",
    "        + (\n",
    "            f\"Terms and Definitions:\\n{question_iter['terms']}\\n\"\n",
    "            if question_iter[\"terms\"]\n",
    "            else \"\"\n",
    "        )\n",
    "        + (\n",
    "            f\"Abbreviations: {question_iter['abbreviations']}\\n\"\n",
    "            if question_iter[\"abbreviations\"]\n",
    "            else \"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    full_question = (\n",
    "        f\"Please provide the answer to the the following multiple choice question:\\n{merged_question}\\n\"\n",
    "        + \"Write only the option number corresponding to the correct answer.\"\n",
    "    )\n",
    "\n",
    "    full_answer = f\"The correct option number is {str(question_iter['answer'])}\\nExplanation: {str(question_iter['explanation'])}\"\n",
    "\n",
    "    dialogue = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"context\",\n",
    "                \"content\": full_context,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": full_question,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": full_answer,\n",
    "            },\n",
    "        ],\n",
    "        tokenize=False,\n",
    "    )\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"text\": dialogue,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv(\"./Data/intermediates/TeleQnA-prompt-with-context-phinetune.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
